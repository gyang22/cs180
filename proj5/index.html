<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Gallery</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f4f4f4;
        }
        h1 {
            text-align: center;
            color: #333;
        }
        .gallery {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 20px;
        }
        .gallery-item {
            width: 400px;
            border: 1px solid #ccc;
            border-radius: 5px;
            overflow: hidden;
            background-color: #fff;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .gallery-item-small {
            width: 300px;
            border: 1px solid #ccc;
            border-radius: 5px;
            overflow: hidden;
            background-color: #fff;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .gallery-item img {
            width: 100%;
            height: auto;
        }
        .gallery-item p {
            padding: 15px;
            text-align: center;
            color: #555;
        }
    </style>
</head>
<body>

<h1>Project 5: Fun With Diffusion Models</h1>
<h2>Part A: The Power of Diffusion Models</h2>

<p>In this project, we explore the implementation and application of diffusion models in denoising images, which can be used to sample "novel" images from pure noise and generate cool artwork/visual anagrams.</p>

<h2>Testing Prompts</h2>
<p>We use a pretrained model called DeepFloyd to save compute, which is originally intended for text-to-image use. We get around this by using a "null" prompt of "a high quality photo" which serves as a general prompt, but here we also display some of the pretrained text to image capabilities:</p>
<div class="gallery">
    <div class="gallery-item">
        <img src="proj5_data/snowy.png">
        <p>Prompt: an oil painting of a snowy mountain village</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/hat.png">
        <p>Prompt: a man wearing a hat</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/rocket.png">
        <p>Prompt: a rocket ship</p>
    </div>
</div>

<h2>Implementing the Forward Process</h2>
<p>First, we need a way to add noise to clean images at different levels. We implement a function that adds scaled Gaussian noise to images, and show the results at levels 0 (no noise), 250, 500, and 750.</p>
<div class="gallery">
    <div class="gallery-item">
        <img src="proj5_data/test_im.jpg">
        <p>0</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/test_im_250.jpg">
        <p>250</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/test_im_500.jpg">
        <p>500</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/test_im_750.jpg">
        <p>750</p>
    </div>
</div>

<h2>Classical Denoising</h2>
<p>We can first try simple methods for denoising, such as Gaussian blur filtering to see the results. Using a kernel size of 5 and sigma of 2, we obtain the lackluster results of the blurred/denoised images:</p>
<div class="gallery">
    <div class="gallery-item">
        <img src="proj5_data/test_im_250.jpg">
        <img src="proj5_data/blur_test_250.jpg">
        <p>250</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/test_im_500.jpg">
        <img src="proj5_data/blur_test_500.jpg">
        <p>500</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/test_im_750.jpg">
        <img src="proj5_data/blur_test_750.jpg">
        <p>750</p>
    </div>
</div>
<p>With lower noise levels, the blur denoising works alright, but as the noise increases it becomes more obvious, and we also sacrifice image clarity in this way.</p>

<h2>One-Step Denoising</h2>
<p>We can improve this performance by using a diffusion model to predict the noise in the image. In this section, we use a pretrained model for simplicity, to which we can feed the noisy image and the timestep/scale of the noise t, and get a noise estimate as an output, then scale this noise by the inverse factor we multiplied by in the original forward step. The results for model-predicted denoising is shown for the three levels:</p>
<div class="gallery">
    <div class="gallery-item">
        <img src="proj5_data/test_im_250.jpg">
        <img src="proj5_data/one_step_250.png">
        <p>250</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/test_im_500.jpg">
        <img src="proj5_data/one_step_500.png">
        <p>500</p>
    </div>
    <div class="gallery-item">
        <img src="proj5_data/test_im_750.jpg">
        <img src="proj5_data/one_step_750.png">
        <p>750</p>
    </div>
</div>

<h2>Iterative Denoising</h2>
<p>In order to improve our performance, we can instead iteratively denoise the image by iterating on our timesteps, and slowly subtracting the predicted noise at each level. The formula involves the noise scaling factor we originally noised the image with, then we attempt to predict the next cleaner step of the image by getting the model's estimate, then subtracting a scaled version of it from the blurry image, then add back some additional noise to aid in our "search" for the optimal image. Once we reach the final timestep, we have found our clean image, or our best estimate of it.</p>
<p>We create our timesteps as a linear interpolation between 990 and 0, with a step size down of 30 each time, and show the denoising process every fifth step.</p>
<div class="gallery">
    <div class="gallery-item-small">
        <img src="proj5_data/iter_1.png">
        <p>t = 690</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/iter_2.png">
        <p>t = 540</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/iter_3.png">
        <p>t = 390</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/iter_4.png">
        <p>t = 240</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/iter_5.png">
        <p>t = 90</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/im_clean.png">
        <p>t = 0 (denoised)</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/im_clean.png">
        <p>t = 0 (denoised)</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/test_im.jpg">
        <p>Original</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/im_clean_one_step.png">
        <p>Denoised (one-step)</p>
    </div>
    <div class="gallery-item-small">
        <img src="proj5_data/im_blur_filter.png">
        <p>Denoised (blur filter)</p>
    </div>
</div>


<h2>Part B: Diffusion Models from Scratch</h2>
<p>In this next part, we implement diffusion models from scratch using the U-net neural network architecture. We train our model on the MNIST handwritten digits dataset, then apply the same denoising and sampling processing to generate digits from pure noise.</p>

<h2>Implementing the UNet</h2>
<p>Using PyTorch, we implement the general structure of the U-net as described below:</p>
<div style="display: flex;
justify-content: center;
align-items: center;">
    <img src="proj5_data/unet_diagram.png" style="width: 70%; height: auto; margin: auto;">
</div>

<h2>Using the UNet to Train a Denoiser</h2>
<p>In order to train the model, we take clean images of digits and apply Gaussian noise to them with sigma = 0.5, then run gradient descent on the mean squared error between the clean image and predicted output. Below is the training loss curve over 5 epochs.</p>
<div style="display: flex;
justify-content: center;
align-items: center;">
    <img src="proj5_data/single_step_loss.png" style="width: 40%; height: auto; margin: auto;">
</div>
<p>Testing our model on test set images also made noisy with sigma 0.5 yields the following results:</p>

</body>
</html>
