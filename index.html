<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Gallery</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f4f4f4;
        }
        h1 {
            text-align: center;
            color: #333;
        }
        .gallery {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 20px;
        }
        .gallery-item {
            width: 300px;
            border: 1px solid #ccc;
            border-radius: 5px;
            overflow: hidden;
            background-color: #fff;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .gallery-item img {
            width: 100%;
            height: auto;
        }
        .gallery-item p {
            padding: 15px;
            text-align: center;
            color: #555;
        }
    </style>
</head>
<body>
    <h1>Project 3: Face Morphing and Modeling a Photo Collection</h1>
    <p>In this project, we used the concept of transformations in geometric space, specifically affine transformations of images, to compute variations on image pairs, including midway hybrids of two faces, morph animations, mean faces of a population, and caricatures.</p>
    <h2>Defining Correspondences</h2>
    <p>In order to "move" an image to another image, we first need to define the triangles which segement the image into its key features. By selecting points corresponding to each other in each image, we can then triangulate between these points, using Delauney triangulation. The result on the average of the two point sets is the below triangulation, which vaguely captures the facial details. We can also see the triangulation on a face. Note that the corners must also be selected to triangulate the background as well.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj3_data/triangles.png">
            <p>Mean face triangles</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/grant_tri.png">
        </div>
    </div>

    <h2>Computing the "Mid-way Face"</h2>
    <p>Using the triangles of the mean points from above, we can find the "mean shape" of the two images. This is helpful in defining a concrete set of triangles that match up in both images. Then, for each image, and for each triangle in the image, we can compute the inverse of the affine transformation matrix that maps points in the original image to the halfway face triangle. We can get the points in each triangle using a polygon mask, then multiplying the halfway points by the inverse affine matrix to get the corresponding points in the original image. Since values may not fall on an exact pixel, we use scikit-image's interpolation griddata function to correct assign the data to integer positions. Once each image has pixels filled in on the halfway image, we can then average the two morphed images to get the "mean face" below.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj3_data/grant_pic.jpg">
            <p>Grant</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/mean_face.jpg">
            <p>Grant-Kenny mean face</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/kenny_pic.jpg">
            <p>Kenny</p>
        </div>
    </div>

    <h2>The Morph Sequence</h2>
    <p>In order to visualize the full morphing sequence from one image to another, we can generalize the previous portion: instead of morphing to 50%, we can morph on uniform intervals from 0% (the original image) to 100% (the target). This means when calculating the mean points, we instead use a weighted average between the two point sets to determine the common triangulation. We then run the morph process from before, with increasing weights on the target and decreasing weights on the original each time, to generate frames for the below morph sequence.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj3_data/morph_animation.gif">
        </div>
    </div>

    <h2>The "mean face" of a population</h2>
    <p>We can visualize what the average member of a population looks like by averaging the pixel values of images of the members. However, in order to ensure the facial features align correctly, we first morph each member to the "average shape" of the population determined by the average of the facial key points, then take the pixelwise mean over all the images. The result below shows the average face of the FEI database, part 1, as well as some of the intermediate results of members warped to the average shape.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj3_data/33.jpg">
            <p>Member example</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/66.jpg">
            <p>Member example</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/99.jpg">
            <p>Member example</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/fei_mean_face.jpg">
            <p>Mean face</p>
        </div>
    </div>
    <p>With this mean face, we can also experiment by warping into the mean shape, as well as warping the mean face into our own shape.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj3_data/grant_to_avg.jpg">
            <p>Grant warped to mean face</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/avg_to_grant.jpg">
            <p>Mean face warped to Grant</p>
        </div>
    </div>

    <h2>Caricatures: Extrapolating from the mean</h2>
    <p>Another fun experiment we can do with face warping is to exaggerate the differences between one's own face and the population mean face. Specifically, we can add the difference (self - mean) * some alpha factor, then add it back to one's own points as the destination shape, which results in the differences between oneself and the mean to become cartoonishly large.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj3_data/grant_caricature.jpg">
        </div>
    </div>

    <h2>Bells and Whistles: Changing Ethnicity</h2>
    <p>Below we have the average Burmese person. We can define correspondences on the face, then warp a face to this shape in order to see the effects. Below is an example with Kenny, first warping the shape alone, then also averaging the pixel values.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj3_data/myanmar_avg.jpg">
            <p>Average Burmese person</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/kenny_female.jpg">
            <p>Burmese Kenny shape</p>
        </div>
        <div class="gallery-item">
            <img src="proj3_data/kenny_blended.jpg">
            <p>Burmese Kenny</p>
    </div>




    <!-- <h1>Project 2: Fun with Filters and Frequencies</h1>
    <p>In this project, we used filter convolutions to create various effects, including blurring, sharpening, edge detection, low/high frequency extraction, hybrid images, and blended images.</p>
    <h2>Edges/Gradient Magnitude</h2>
    <p>In order to find the edges of an image, we can first calculate the partial derivatives of the image with the finite difference operators, [[1 -1]] for dx direction or [[1] [-1]] for dy direction, which are convolved with the image to get the change in pixel values in the x and y directions. With directional derivatives in both directions, the overall gradient magnitude can be computed as sqrt(dx^2 + dy^2) elementwise over the two images, which can be binarized where the magnitude meets a certain threshold to produce an edge image. Below are the dx and dy of the cameraman image, the gradient magnitude image, and the binarized edge image.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/cameraman_dx.jpg" alt="Cameraman dx">
            <p>Cameraman dx</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/cameraman_dy.jpg" alt="Cameraman dy">
            <p>Cameraman dy</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/cameraman_magnitude.jpg" alt="Cameraman magnitude">
            <p>Cameraman magnitude</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/cameraman_binary.jpg" alt="Cameraman binarized">
            <p>Cameraman binarized</p>
        </div>
    </div>
    <p>To eliminate the noisy parts, we first apply a Gaussian blur to the image by convolving it with a smaller Gaussian kernel. This computes a random weighted moving average over the image pixels, which averages out the effects of noise and blurs sharp features. This normally requires two separate convolutions, but the gaussian filter can first be convolved with the dx dy finite difference operators to get the below derivative-of-gaussian filters, which does the same operation in one convolution.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/dog_x.jpg" alt="DoG x">
            <p>Derivative of Gaussian x</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/dog_y.jpg" alt="DoG y">
            <p>Derivative of Gaussian y</p>
        </div>
    </div>
    <p>The resulting image is different from the above edge image in that the edges of the man are more clearly defined and the noise elements around him are less prominent.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/cameraman_binary_gauss.jpg" alt="Cameraman binarized gaussian">
            <p>Cameraman binarized with DoG</p>
        </div>
    </div>
    
    <h2>Image Sharpening</h2>
    <p>We can work with the frequencies of an image to enhance certain features. Applying a gaussian filter to blur the image acts as a low pass filter, allowing only the low frequencies to show. We can then extract the high frequencies by subtracting the blurred low frequencies from the original image. This combination of blurring and subtracting can be done with one filter by using the unit impulse minus the gaussian filter. Below are the high frequencies of the taj mahal computed by convolving the original image with the high frequency filter. If we then add the high frequencies back to the original image, we get a sharpened version of the image with more prominent features.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/taj.jpg" alt="Taj mahal">
            <p>Taj Mahal original</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/taj_high_freq.jpg" alt="Taj mahal high freq">
            <p>Taj Mahal high frequencies</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/taj_sharp.jpg" alt="Taj mahal sharp">
            <p>Taj Mahal sharpened</p>
        </div>
    </div>
    <p>Another example of a sharpened image is this sheep: the small features are more prominent and the edges are more pronounced.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/sheep.jpg" alt="sheep">
            <p>Sheep</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/sheep_high.jpg" alt="sheep high freq">
            <p>Sheep high frequencies</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/sheep_sharp.jpg" alt="sheep sharpened">
            <p>Sheep sharpened</p>
        </div>
    </div>
    <p>We can also first blur the image, then sharpen it again. The result does not look like the original anymore, as blurring it eliminated many of the high frequencies, leaving less for the sharpen operation to work with.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/sheep_blur.jpg" alt="sheep blur">
            <p>Sheep blurred</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/sheep_resharp.jpg" alt="sheep resharpened">
            <p>Sheep resharpened</p>
        </div>
    </div>

    <h2>Hybrid Images</h2>
    <p>By using the low and high frequencies of an image, we can create a hybrid overlaid image by extracting the low and high frequencies as detailed above, then overlaying the two with an average. The result is a hybrid image which has prominent low frequency features when viewed blurred or from afar, then displays the high frequencies when viewed in focus or up close. Below is an example with a man and a cat.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/DerekPicture.jpg" alt="derek">
            <p>Man (derek)</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/nutmeg.jpg" alt="nutmeg">
            <p>Cat (nutmeg)</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/derek_nutmeg.jpg" alt="derek nutmeg">
            <p>Hybrid cat-man</p>
        </div>
    </div>
    <p>Another example of this hybrid frequency blending is this picture of a golden retriever and obama:</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/obama.jpg" alt="obama">
            <p>Obama</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/dog.jpeg" alt="dog">
            <p>Golden retriever</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/dog_obama.jpg" alt="obama dog">
            <p>Hybrid obama-dog</p>
        </div>
    </div>
    <p>We can also observe the process through the FFT frequency plots:</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/obama_fft.png" alt="obama fft">
            <p>Obama FFT plot</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/dog_fft.png" alt="dog fft">
            <p>Golden retriever FFT plot</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/obama_low_fft.png" alt="obama low fft">
            <p>Obama low pass FFT plot</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/dog_high_fft.png" alt="dog high fft">
            <p>Golden retriever high pass FFT plot</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/obama_dog_fft.png" alt="obama dog fft">
            <p>Hybrid obama-dog FFT plot</p>
        </div>
    </div>
    <p>One example which did not work as well was this egg combined with the rock. Although their head shapes are similar, their facial features do not match up and leave visible artifacts on the rock's face.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/rock.jpg" alt="rock">
            <p>The Rock</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/egg.jpg" alt="egg">
            <p>The Egg</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/rock_egg.jpg" alt="rock egg">
            <p>Rock egg</p>
        </div>
    </div>


    <h2>Multiresolution Blending</h2>
    <p>In order to blend two images together with a less obvious seam between them, we can use the different frequencies again. By repeatedly applying the blurring operation to the same image, we can create a gaussian stack of progressively filtered frequencies. If we then subtract each stack image from its previous image, we can get the band between frequencies, essentially decomposing the image into its levels of frequencies. These bands compose the laplacian stack. Below, in order, we have the gaussian stacks of the apple, orange, and mask (which is a transition from all ones to all zeros corresponding to each half), then the laplacian stacks of the apple, orange, and combined orapple. By multiplying each image in the laplacian stack with its respective mask at that level, and then adding them together, we get more and more interweaved features as they get larger. Once we have the blended laplacian stack, we can collapse the stack by summing it, resulting in the original image but now blended. The result is the orapple:</p>   
    <div style="width: 100vw;">
        <img src="proj2_data/apple_g_stack.png" style="width: 95vw;">
        <img src="proj2_data/orange_g_stack.png" style="width: 95vw;">
        <img src="proj2_data/mask_g_stack.png" style="width: 95vw;">
        <img src="proj2_data/apple_l_stack.png" style="width: 95vw;">
        <img src="proj2_data/orange_l_stack.png" style="width: 95vw;">
        <img src="proj2_data/orapple_l_stack.png" style="width: 95vw;">
    </div>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/orapple.jpg" alt="orapple">
            <p>Orapple</p>
        </div>
    </div>
    <p>The more natural seam is due to the increasing band size of the mask as it is increasingly blurred, and this band increase corresponds to more and more crude features, meaning that large features like color are blended together further, while more fine details like the texture are still distinct on each end.</p>
    <p>A similar example can be done with a plum and a peach:</p>
    <img src="proj2_data/pleach_plots.png" style="width: 60vw; display: block; margin-left: auto; margin-right: auto;">
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/plum.jpg" alt="plum">
            <p>Plum</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/peach.jpg" alt="peach">
            <p>Peach</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/pleach.jpg" alt="plum peach">
            <p>Hybrid plum-peach</p>
        </div>
    </div>
    <p>We can use an irregular mask to do different kinds of blends, for example this elliptical mask putting a familiar face on an egg.</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj2_data/rock.jpg" alt="rock">
            <p>The Rock</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/brown_egg.jpg" alt="egg">
            <p>The Egg (2)</p>
        </div>
        <div class="gallery-item">
            <img src="proj2_data/rock_egg_two.jpg" alt="rock egg">
            <p>Rock egg 2</p>
        </div>
    </div>
    <p>One of the most important things I learned from this project is the analog of images to signals: although they may seem like far-away concepts, they share much in common and can be worked with in similar ways.</p> 
     -->


<!-- 
    <h1>Project 1: Colorizing the Prokudin-Gorskii photo collection</h1>
    <p>In this project, we created algorithms to transform the Prokudin-Gorskii glass plate negatives taken of various images in separate R, G, and B channels to color images. The basic algorithm involves cutting the image into thirds, then iterating over various offsets of the image to compare alignment similarity scores, then upscaling the resolution to search again with more precision.
    </p>
    <p>An example glass plate image, of a cathedral in its three channels:</p>
    <img src="proj1_data/cathedral.jpg" alt="Cathedral Glass Plate" style="display: block; margin: 0 auto; width: 10%; height: auto;">
    <p>First, the images are split into thirds, and designated as RGB sections. Each of these are cropped together, to remove whitespace and borders. Then, the images are processed in pairs: red and blue are both aligned with green, as each image is downscaled to reduce pixel count, and repeatedly aligned using a similarity score of Normalized Cross-Correlation, in a loop while upscaled until the original resolution is reached. Then the three aligned images are overlaid to form a color image. The pixel amounts shifted in the red and blue images are shown below.</p>
    <p>The processed images:</p>
    <div class="gallery">
        <div class="gallery-item">
            <img src="proj1_data/cathedral_processed.jpg" alt="Cathedral Processed">
            <p>Red shift: (1, 1)</p>
            <p>Blue shift: (2, 0)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/church_processed.jpg" alt="Church Processed">
            <p>Red shift: (0, 0)</p>
            <p>Blue shift: (32, 11)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/emir_processed.jpg" alt="Emir Processed">
            <p>Red shift: (-8, 16)</p>
            <p>Blue shift: (25, -21)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/harvesters_processed.jpg" alt="Harvesters Processed">
            <p>Red shift: (12, -3)</p>
            <p>Blue shift: (-6, -11)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/icon_processed.jpg" alt="Icon Processed">
            <p>Red shift: (11, 5)</p>
            <p>Blue shift: (-5, -17)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/lady_processed.jpg" alt="Lady Processed">
            <p>Red shift: (-2, -4)</p>
            <p>Blue shift: (0, 1)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/melons_processed.jpg" alt="Melons Processed">
            <p>Red shift: (11, 4)</p>
            <p>Blue shift: (0, -4)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/monastery_processed.jpg" alt="Monastery Processed">
            <p>Red shift: (-1, 0)</p>
            <p>Blue shift: (10, 0)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/onion_church_processed.jpg" alt="Onion Church Processed">
            <p>Red shift: (-6, 10)</p>
            <p>Blue shift: (10, -24)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/sculpture_processed.jpg" alt="Sculpture Processed">
            <p>Red shift: (37, -16)</p>
            <p>Blue shift: (37, 11)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/self_portrait_processed.jpg" alt="Self Portrait Processed">
            <p>Red shift: (15, 8)</p>
            <p>Blue shift: (31, 1)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/three_generations_processed.jpg" alt="Three Generations Processed">
            <p>Red shift: (-7, 0)</p>
            <p>Blue shift: (12, -5)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/tobolsk_processed.jpg" alt="Tobolsk Processed">
            <p>Red shift: (0, 1)</p>
            <p>Blue shift: (1, -2)</p>
        </div>
        <div class="gallery-item">
            <img src="proj1_data/train_processed.jpg" alt="Train Processed">
            <p>Red shift: (-8, 24)</p>
            <p>Blue shift: (8, 2)</p>
        </div>
    </div> -->
</body>
</html>
